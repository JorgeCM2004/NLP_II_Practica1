{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d20da38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\Desktop\\CUARTO CURSO\\PRIMER CUATRIMESTRE\\Procesamiento del lenguaje natural II\\Practica 1 NLP II\\NLP_II_Practica1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.genre_classification.F_Basic_Models import Basic_Models\n",
    "from src.genre_classification.F_Dataset_Downloader import Dataset_Downloader\n",
    "from src.genre_classification.F_Pretrained_models import Pretrained \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169589fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ayni - nan</td>\n",
       "      <td>Ayni - nan. Four Peruvian strangers are select...</td>\n",
       "      <td>action_adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>His Kind of Woman - 1951</td>\n",
       "      <td>His Kind of Woman - 1951. A deported gangster'...</td>\n",
       "      <td>suspense_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Little Alice's Storytime: Through the Looking ...</td>\n",
       "      <td>Little Alice's Storytime: Through the Looking ...</td>\n",
       "      <td>comedy_family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Punchi Andare - 2018</td>\n",
       "      <td>Punchi Andare - 2018. A story about a kid who ...</td>\n",
       "      <td>comedy_family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He Has Nothing But Kung Fu - 1977</td>\n",
       "      <td>He Has Nothing But Kung Fu - 1977. He's lost h...</td>\n",
       "      <td>action_adventure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                         Ayni - nan   \n",
       "1                           His Kind of Woman - 1951   \n",
       "2  Little Alice's Storytime: Through the Looking ...   \n",
       "3                               Punchi Andare - 2018   \n",
       "4                  He Has Nothing But Kung Fu - 1977   \n",
       "\n",
       "                                                text             genre  \n",
       "0  Ayni - nan. Four Peruvian strangers are select...  action_adventure  \n",
       "1  His Kind of Woman - 1951. A deported gangster'...    suspense_crime  \n",
       "2  Little Alice's Storytime: Through the Looking ...     comedy_family  \n",
       "3  Punchi Andare - 2018. A story about a kid who ...     comedy_family  \n",
       "4  He Has Nothing But Kung Fu - 1977. He's lost h...  action_adventure  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_downloader = Dataset_Downloader()\n",
    "train_path, test_path = dataset_downloader(overwrite=True)\n",
    "\n",
    "train_data = pd.read_csv(train_path.resolve())\n",
    "test_data = pd.read_csv(test_path.resolve())\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1f8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_data.drop(columns=[\"genre\"]), train_data[\"genre\"]\n",
    "\n",
    "x_test, y_test = test_data.drop(columns=[\"genre\"]), test_data[\"genre\"]\n",
    "\n",
    "unique_labels = sorted(list(set(train_data[\"genre\"])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546fe63",
   "metadata": {},
   "source": [
    "# Entrenamiento de los Modelos Basicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_models_name = ['Naive_Bayes', 'LogReg', 'Linear_SVM', 'Random_Forest']\n",
    "\n",
    "for model_name in basic_models_name:\n",
    "    model = Basic_Models(model_type= model_name)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_hat = model.predict(x_test)\n",
    "    model.evaluate(y_true= y_test, y_hat=y_hat, labels = set(y_test), evaluate_type= \"all_metrics\")\n",
    "    model.save_model(name= model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec6ba7e",
   "metadata": {},
   "source": [
    "# Pruebas de Modelos Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96ed733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading model: microsoft/deberta-v3-large...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectadas etiquetas de texto. Convirtiendo a IDs numéricos internamente...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 221598/221598 [00:23<00:00, 9550.97 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 167/55400 [07:39<42:13:24,  2.75s/it, loss=1.91] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m test_texts = test_data[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m].tolist()   \n\u001b[32m      4\u001b[39m model_transformer = Pretrained(model_type=\u001b[33m\"\u001b[39m\u001b[33mdeberta-v3-large\u001b[39m\u001b[33m\"\u001b[39m, labels =\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(train_data[\u001b[33m\"\u001b[39m\u001b[33mgenre\u001b[39m\u001b[33m\"\u001b[39m])))) \n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmodel_transformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgenre\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m predictions = model_transformer.transform(test_texts)\n\u001b[32m     10\u001b[39m model_transformer.save_model_and_tokenizer()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alber\\Desktop\\CUARTO CURSO\\PRIMER CUATRIMESTRE\\Procesamiento del lenguaje natural II\\Practica 1 NLP II\\NLP_II_Practica1\\src\\genre_classification\\F_Pretrained_models.py:129\u001b[39m, in \u001b[36mPretrained.fit\u001b[39m\u001b[34m(self, train_texts, train_labels, batch_size, epochs, learning_rate, weight_decay)\u001b[39m\n\u001b[32m    126\u001b[39m scaler.scale(loss).backward()\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (step + \u001b[32m1\u001b[39m) % accumulation_steps == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     scaler.update()\n\u001b[32m    131\u001b[39m     lr_scheduler.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alber\\Desktop\\CUARTO CURSO\\PRIMER CUATRIMESTRE\\Procesamiento del lenguaje natural II\\Practica 1 NLP II\\NLP_II_Practica1\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:462\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    456\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m, (\n\u001b[32m    459\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    460\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alber\\Desktop\\CUARTO CURSO\\PRIMER CUATRIMESTRE\\Procesamiento del lenguaje natural II\\Practica 1 NLP II\\NLP_II_Practica1\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:356\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    350\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m     **kwargs: Any,\n\u001b[32m    354\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    355\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf_per_device\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    357\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alber\\Desktop\\CUARTO CURSO\\PRIMER CUATRIMESTRE\\Procesamiento del lenguaje natural II\\Practica 1 NLP II\\NLP_II_Practica1\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:356\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    350\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m     **kwargs: Any,\n\u001b[32m    354\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    355\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    357\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_texts = train_data[\"text\"].tolist() \n",
    "test_texts = test_data[\"text\"].tolist()   \n",
    "\n",
    "model_transformer = Pretrained(model_type=\"deberta-v3-large\", labels =sorted(list(set(train_data[\"genre\"])))) \n",
    "\n",
    "model_transformer.fit(train_texts, train_labels = list(train_data[\"genre\"]))\n",
    "\n",
    "predictions = model_transformer.transform(test_texts)\n",
    "\n",
    "model_transformer.save_model_and_tokenizer()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
