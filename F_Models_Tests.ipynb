{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Evaluación de Modelos\n",
                "\n",
                "Este cuaderno carga los conjuntos de datos de entrenamiento y prueba, y a continuación evalúa los siguientes modelos:\n",
                "1. **Modelos Básicos**: Random Forest, Naive Bayes, Logistic Regression, Linear SVM.\n",
                "2. **Modelo Transformer**: DeBERTa-v3-large y Roberta-base."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\alber\\Desktop\\CUARTO CURSO\\PRIMER CUATRIMESTRE\\Procesamiento del lenguaje natural II\\Practica 1 NLP II\\NLP_II_Practica1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "import torch\n",
                "import shutil\n",
                "from typing import List\n",
                "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
                "\n",
                "from src.genre_classification.F_Basic_Models import Basic_Models\n",
                "from src.genre_classification.F_Dataset_Downloader import Dataset_Downloader\n",
                "from src.genre_classification.F_Pretrained_models import Pretrained\n",
                "from src.genre_classification.F_Compute_Metrics import Compute_Metrics"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Carga de Datos\n",
                "Cargamos los datos de entrenamiento y prueba. El set de entrenamiento sólo se usa si es necesario entrenar algún modelo basico."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cargando Train: C:\\Users\\alber\\Desktop\\CUARTO CURSO\\PRIMER CUATRIMESTRE\\Procesamiento del lenguaje natural II\\Practica 1 NLP II\\NLP_II_Practica1\\datasets\\dataset_train.csv\n",
                        "Cargando Test: C:\\Users\\alber\\Desktop\\CUARTO CURSO\\PRIMER CUATRIMESTRE\\Procesamiento del lenguaje natural II\\Practica 1 NLP II\\NLP_II_Practica1\\datasets\\dataset_test.csv\n",
                        "Etiquetas: ['action_adventure', 'comedy_family', 'documentary_factual', 'drama_romance', 'scifi_horror_fantasy', 'suspense_crime']\n"
                    ]
                }
            ],
            "source": [
                "dataset_downloader = Dataset_Downloader()\n",
                "train_path, test_path = dataset_downloader(overwrite=False)\n",
                "\n",
                "print(f\"Cargando Train: {train_path}\")\n",
                "print(f\"Cargando Test: {test_path}\")\n",
                "\n",
                "train_data = pd.read_csv(train_path)\n",
                "test_data = pd.read_csv(test_path)\n",
                "\n",
                "x_train, y_train = train_data.drop(columns=[\"genre\"]), train_data[\"genre\"]\n",
                "x_test, y_test = test_data.drop(columns=[\"genre\"]), test_data[\"genre\"]\n",
                "\n",
                "unique_labels = sorted(list(set(y_train)))\n",
                "print(f\"Etiquetas: {unique_labels}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Modelos Básicos\n",
                "Iteramos sobre cada uno de los tipos de modelos básicos. Si el modelo ya está guardado, lo cargamos. Si no, lo entrenamos y guardamos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================== Naive_Bayes ====================\n",
                        "NLTK configurado exitosamente.\n",
                        "Cargando modelo guardado desde ./Models/Modelos_Basicos/Naive_Bayes.joblib...\n",
                        "Modelo cargado correctamente.\n",
                        "Realizando predicciones con Naive_Bayes...\n",
                        "Iniciando predicción...\n",
                        "-> Predicción terminada.\n",
                        "Evaluación de Naive_Bayes:\n",
                        "{'action_adventure': {'precision': 0.511419068736142, 'recall': 0.43083963762024846, 'f1-score': 0.4676838850306686, 'support': 10707.0}, 'comedy_family': {'precision': 0.43112513144058884, 'recall': 0.2551867219917012, 'f1-score': 0.32060471784178285, 'support': 4820.0}, 'documentary_factual': {'precision': 0.4559240126645559, 'recall': 0.7578947368421053, 'f1-score': 0.5693476225158672, 'support': 3610.0}, 'drama_romance': {'precision': 0.5498112111530642, 'recall': 0.6263545371825626, 'f1-score': 0.585592204477785, 'support': 12089.0}, 'scifi_horror_fantasy': {'precision': 0.5063350983358548, 'recall': 0.5561902783547985, 'f1-score': 0.5300930508810137, 'support': 9628.0}, 'suspense_crime': {'precision': 0.5910608590074367, 'recall': 0.5354736697373849, 'f1-score': 0.5618958303275141, 'support': 14546.0}, 'accuracy': 0.5287906137184115, 'macro avg': {'precision': 0.5076125635562737, 'recall': 0.5269899302881335, 'f1-score': 0.5058695518457719, 'support': 55400.0}, 'weighted avg': {'precision': 0.5292221318005367, 'recall': 0.5287906137184115, 'f1-score': 0.5228239677989424, 'support': 55400.0}}\n",
                        "\n",
                        "==================== LogReg ====================\n",
                        "NLTK configurado exitosamente.\n",
                        "Cargando modelo guardado desde ./Models/Modelos_Basicos/LogReg.joblib...\n",
                        "Modelo cargado correctamente.\n",
                        "Realizando predicciones con LogReg...\n",
                        "Iniciando predicción...\n",
                        "-> Predicción terminada.\n",
                        "Evaluación de LogReg:\n",
                        "{'action_adventure': {'precision': 0.4840250821140639, 'recall': 0.45418884841692353, 'f1-score': 0.46863255276091353, 'support': 10707.0}, 'comedy_family': {'precision': 0.3603551990833572, 'recall': 0.5219917012448133, 'f1-score': 0.4263684121335367, 'support': 4820.0}, 'documentary_factual': {'precision': 0.5898876404494382, 'recall': 0.7853185595567868, 'f1-score': 0.6737167300380228, 'support': 3610.0}, 'drama_romance': {'precision': 0.600203647135055, 'recall': 0.5363553643808421, 'f1-score': 0.5664861086842565, 'support': 12089.0}, 'scifi_horror_fantasy': {'precision': 0.5010782934833568, 'recall': 0.5550477773161612, 'f1-score': 0.526684078253585, 'support': 9628.0}, 'suspense_crime': {'precision': 0.601554104323386, 'recall': 0.5002749896878868, 'f1-score': 0.54625980557745, 'support': 14546.0}, 'accuracy': 0.5292238267148014, 'macro avg': {'precision': 0.5228506610981095, 'recall': 0.5588628734339024, 'f1-score': 0.5346912812412941, 'support': 55400.0}, 'weighted avg': {'precision': 0.5393377743169846, 'recall': 0.5292238267148014, 'f1-score': 0.5301429943965902, 'support': 55400.0}}\n",
                        "\n",
                        "==================== Linear_SVM ====================\n",
                        "NLTK configurado exitosamente.\n",
                        "Cargando modelo guardado desde ./Models/Modelos_Basicos/Linear_SVM.joblib...\n",
                        "Modelo cargado correctamente.\n",
                        "Realizando predicciones con Linear_SVM...\n",
                        "Iniciando predicción...\n",
                        "-> Predicción terminada.\n",
                        "Evaluación de Linear_SVM:\n",
                        "{'action_adventure': {'precision': 0.4785963428813022, 'recall': 0.4229009059493789, 'f1-score': 0.4490281634272114, 'support': 10707.0}, 'comedy_family': {'precision': 0.3652027027027027, 'recall': 0.44854771784232367, 'f1-score': 0.40260707635009313, 'support': 4820.0}, 'documentary_factual': {'precision': 0.5809058048054433, 'recall': 0.756786703601108, 'f1-score': 0.6572837724046674, 'support': 3610.0}, 'drama_romance': {'precision': 0.5793821529988813, 'recall': 0.5569526015385888, 'f1-score': 0.567946014339941, 'support': 12089.0}, 'scifi_horror_fantasy': {'precision': 0.4919724770642202, 'recall': 0.5346904860822601, 'f1-score': 0.5124427632888712, 'support': 9628.0}, 'suspense_crime': {'precision': 0.5756934472073162, 'recall': 0.5236491131582566, 'f1-score': 0.5484393563019765, 'support': 14546.0}, 'accuracy': 0.5220216606498195, 'macro avg': {'precision': 0.5119588212766444, 'recall': 0.5405879213619861, 'f1-score': 0.5229578576854601, 'support': 55400.0}, 'weighted avg': {'precision': 0.525208966885563, 'recall': 0.5220216606498195, 'f1-score': 0.5216318094092564, 'support': 55400.0}}\n",
                        "\n",
                        "==================== Random_Forest ====================\n",
                        "NLTK configurado exitosamente.\n",
                        "Cargando modelo guardado desde ./Models/Modelos_Basicos/Random_Forest.joblib...\n",
                        "Modelo cargado correctamente.\n",
                        "Realizando predicciones con Random_Forest...\n",
                        "Iniciando predicción...\n",
                        "-> Predicción terminada.\n",
                        "Evaluación de Random_Forest:\n",
                        "{'action_adventure': {'precision': 0.41064720403563376, 'recall': 0.3573363220323153, 'f1-score': 0.3821414302836596, 'support': 10707.0}, 'comedy_family': {'precision': 0.3539765319426336, 'recall': 0.33796680497925313, 'f1-score': 0.3457864572277648, 'support': 4820.0}, 'documentary_factual': {'precision': 0.5358824637408175, 'recall': 0.7880886426592798, 'f1-score': 0.6379638972979034, 'support': 3610.0}, 'drama_romance': {'precision': 0.5479191438763377, 'recall': 0.5717594507403425, 'f1-score': 0.5595854922279793, 'support': 12089.0}, 'scifi_horror_fantasy': {'precision': 0.42784785932721714, 'recall': 0.4649979227253843, 'f1-score': 0.4456500099542106, 'support': 9628.0}, 'suspense_crime': {'precision': 0.5376918964332086, 'recall': 0.48398185068059946, 'f1-score': 0.5094250877383407, 'support': 14546.0}, 'accuracy': 0.48247292418772564, 'macro avg': {'precision': 0.46899418322597475, 'recall': 0.500688498969529, 'f1-score': 0.48009206245497643, 'support': 55400.0}, 'weighted avg': {'precision': 0.4801783797313776, 'recall': 0.48247292418772564, 'f1-score': 0.47882623329883545, 'support': 55400.0}}\n"
                    ]
                }
            ],
            "source": [
                "basic_models_names = ['Naive_Bayes', 'LogReg', 'Linear_SVM', 'Random_Forest']\n",
                "results = {}\n",
                "\n",
                "for model_name in basic_models_names:\n",
                "    print(f\"\\n{'='*20} {model_name} {'='*20}\")\n",
                "    model = Basic_Models(model_type=model_name)\n",
                "    \n",
                "    model_file = f\"./Models/Modelos_Basicos/{model_name}.joblib\"\n",
                "    \n",
                "    if os.path.exists(model_file):\n",
                "        print(f\"Cargando modelo guardado desde {model_file}...\")\n",
                "        model.load_model(name=f\"{model_name}.joblib\")\n",
                "    else:\n",
                "        print(f\"Modelo no encontrado. Entrenando {model_name}...\")\n",
                "        model.fit(x_train, y_train)\n",
                "        model.save_model(name=model_name)\n",
                "    \n",
                "\n",
                "    print(f\"Realizando predicciones con {model_name}...\")\n",
                "    y_hat = model.predict(x_test)\n",
                "    results[model_name] = y_hat\n",
                "    \n",
                "    print(f\"Evaluación de {model_name}:\")\n",
                "    metrics = model.evaluate(y_true=y_test, y_hat=y_hat, labels=set(y_test), evaluate_type=\"sk_learn_metrics\")\n",
                "    print(metrics)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Modelo Transformer\n",
                "Verificamos si existe el modelo pre-entrenado y predecimos sobre el conjunto de test."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "========================================\n",
                        "PROCESANDO MODELO: roberta-base\n",
                        "========================================\n",
                        "Using device: cuda\n",
                        "Loading model: roberta-base...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`torch_dtype` is deprecated! Use `dtype` instead!\n",
                        "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cargando desde: ./Models/Modelos_Transformer/Roberta_base/...\n",
                        "Modelo cargado correctamente en GPU.\n",
                        "Realizando inferencia...\n",
                        "Error al cargar el modelo roberta-base: name 'test_texts' is not defined\n",
                        "\n",
                        "========================================\n",
                        "PROCESANDO MODELO: deberta-v3-large\n",
                        "========================================\n",
                        "Using device: cuda\n",
                        "Loading model: microsoft/deberta-v3-large...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\alber\\Desktop\\CUARTO CURSO\\PRIMER CUATRIMESTRE\\Procesamiento del lenguaje natural II\\Practica 1 NLP II\\NLP_II_Practica1\\.venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
                        "  warnings.warn(\n",
                        "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cargando desde: ./Models/Modelos_Transformer/Deberta_large/...\n",
                        "Modelo cargado correctamente en GPU.\n",
                        "Realizando inferencia...\n",
                        "Error al cargar el modelo deberta-v3-large: name 'test_texts' is not defined\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
                "\n",
                "# Lista de modelos a evaluar\n",
                "OFFICIAL_MODEL_TYPES = ['roberta-base', 'deberta-v3-large']\n",
                "MODELS_DIRS = ['Roberta_base/', 'Deberta_large/']\n",
                "base_dir = \"./Models/Modelos_Transformer/\"\n",
                "    \n",
                "for current_model_name, model_dir in zip(OFFICIAL_MODEL_TYPES, MODELS_DIRS):\n",
                "    \n",
                "    print(f\"\\n{'='*40}\")\n",
                "    print(f\"PROCESANDO MODELO: {current_model_name}\")\n",
                "    print(f\"{'='*40}\")\n",
                "    \n",
                "    full_model_path = os.path.join(base_dir, model_dir)\n",
                "\n",
                "    transformer_wrapper = Pretrained(model_type=current_model_name, labels=unique_labels)\n",
                "\n",
                "    if os.path.exists(full_model_path) and len(os.listdir(full_model_path)) > 0:\n",
                "        print(f\"Cargando desde: {full_model_path}...\")\n",
                "        \n",
                "        try:\n",
                "            transformer_wrapper.model = AutoModelForSequenceClassification.from_pretrained(full_model_path + current_model_name + '_modelo')\n",
                "            transformer_wrapper.tokenizer = AutoTokenizer.from_pretrained(full_model_path + current_model_name + '_tokenizer')\n",
                "            transformer_wrapper.model.to(transformer_wrapper.device)\n",
                "            print(\"Modelo cargado correctamente en GPU.\")\n",
                "\n",
                "            print(\"Realizando inferencia...\")\n",
                "            predictions_ids = transformer_wrapper.transform(test_texts, batch_size=32)\n",
                "            \n",
                "            predictions_labels = [transformer_wrapper.id2label[pid] for pid in predictions_ids]\n",
                "\n",
                "            results[current_model_name] = predictions_labels\n",
                "            print(f\"Resultados guardados para {current_model_name}\")\n",
                "\n",
                "        except Exception as e:\n",
                "            print(f\"Error al cargar el modelo {current_model_name}: {e}\")\n",
                "            \n",
                "    else:\n",
                "        print(f\"El modelo no se encontró en: {full_model_path}\")\n",
                "        print(\"Por favor, entrénalo primero.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Comparación Final\n",
                "Mostramos un resumen de las métricas de todos los modelos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.5287906137184115\n",
                        "0.5292238267148014\n",
                        "0.5220216606498195\n",
                        "0.48247292418772564\n",
                        "\n",
                        "--- Tabla Comparativa de Resultados ---\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Model</th>\n",
                            "      <th>Accuracy</th>\n",
                            "      <th>Macro F1</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>LogReg</td>\n",
                            "      <td>0.529224</td>\n",
                            "      <td>0.534691</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Linear_SVM</td>\n",
                            "      <td>0.522022</td>\n",
                            "      <td>0.522958</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Naive_Bayes</td>\n",
                            "      <td>0.528791</td>\n",
                            "      <td>0.505870</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Random_Forest</td>\n",
                            "      <td>0.482473</td>\n",
                            "      <td>0.480092</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "           Model  Accuracy  Macro F1\n",
                            "1         LogReg  0.529224  0.534691\n",
                            "2     Linear_SVM  0.522022  0.522958\n",
                            "0    Naive_Bayes  0.528791  0.505870\n",
                            "3  Random_Forest  0.482473  0.480092"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Matriz de Confusión del mejor modelo (LogReg):\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th>Predicción</th>\n",
                            "      <th>action_adventure</th>\n",
                            "      <th>comedy_family</th>\n",
                            "      <th>documentary_factual</th>\n",
                            "      <th>drama_romance</th>\n",
                            "      <th>scifi_horror_fantasy</th>\n",
                            "      <th>suspense_crime</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Real</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>action_adventure</th>\n",
                            "      <td>4863</td>\n",
                            "      <td>1107</td>\n",
                            "      <td>277</td>\n",
                            "      <td>1109</td>\n",
                            "      <td>1441</td>\n",
                            "      <td>1910</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>comedy_family</th>\n",
                            "      <td>463</td>\n",
                            "      <td>2516</td>\n",
                            "      <td>320</td>\n",
                            "      <td>863</td>\n",
                            "      <td>465</td>\n",
                            "      <td>193</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>documentary_factual</th>\n",
                            "      <td>118</td>\n",
                            "      <td>222</td>\n",
                            "      <td>2835</td>\n",
                            "      <td>319</td>\n",
                            "      <td>43</td>\n",
                            "      <td>73</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>drama_romance</th>\n",
                            "      <td>1242</td>\n",
                            "      <td>1585</td>\n",
                            "      <td>1063</td>\n",
                            "      <td>6484</td>\n",
                            "      <td>598</td>\n",
                            "      <td>1117</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>scifi_horror_fantasy</th>\n",
                            "      <td>1094</td>\n",
                            "      <td>937</td>\n",
                            "      <td>125</td>\n",
                            "      <td>601</td>\n",
                            "      <td>5344</td>\n",
                            "      <td>1527</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>suspense_crime</th>\n",
                            "      <td>2267</td>\n",
                            "      <td>615</td>\n",
                            "      <td>186</td>\n",
                            "      <td>1427</td>\n",
                            "      <td>2774</td>\n",
                            "      <td>7277</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "Predicción            action_adventure  comedy_family  documentary_factual  \\\n",
                            "Real                                                                         \n",
                            "action_adventure                  4863           1107                  277   \n",
                            "comedy_family                      463           2516                  320   \n",
                            "documentary_factual                118            222                 2835   \n",
                            "drama_romance                     1242           1585                 1063   \n",
                            "scifi_horror_fantasy              1094            937                  125   \n",
                            "suspense_crime                    2267            615                  186   \n",
                            "\n",
                            "Predicción            drama_romance  scifi_horror_fantasy  suspense_crime  \n",
                            "Real                                                                       \n",
                            "action_adventure               1109                  1441            1910  \n",
                            "comedy_family                   863                   465             193  \n",
                            "documentary_factual             319                    43              73  \n",
                            "drama_romance                  6484                   598            1117  \n",
                            "scifi_horror_fantasy            601                  5344            1527  \n",
                            "suspense_crime                 1427                  2774            7277  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "final_metrics = []\n",
                "\n",
                "for model_name, preds in results.items():\n",
                "    cm = Compute_Metrics(y_pred=preds, y_true=y_test, labels=unique_labels)\n",
                "    metrics_dict = cm.compute_all()\n",
                "    \n",
                "    final_metrics.append({\n",
                "        \"Model\": model_name,\n",
                "        \"Accuracy\": metrics_dict[\"accuracy\"],\n",
                "        \"Macro F1\": metrics_dict[\"macro_f1\"]\n",
                "    })\n",
                "\n",
                "df_metrics = pd.DataFrame(final_metrics)\n",
                "df_metrics = df_metrics.sort_values(by=\"Macro F1\", ascending=False)\n",
                "\n",
                "print(\"\\n--- Tabla Comparativa de Resultados ---\")\n",
                "display(df_metrics)\n",
                "\n",
                "best_model = df_metrics.iloc[0]['Model']\n",
                "print(f\"\\nMatriz de Confusión del mejor modelo ({best_model}):\")\n",
                "cm_best = Compute_Metrics(y_pred=results[best_model], y_true=y_test, labels=unique_labels)\n",
                "display(cm_best.confusion_matrix())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
